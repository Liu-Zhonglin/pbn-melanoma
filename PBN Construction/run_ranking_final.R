# ===================================================================
# SCRIPT: run_final_ranking.R
#
# PURPOSE:
# Runs dynGENIE3 on the final, pre-selected core gene set. This script
# does not perform selection; rather, it generates the definitive
# interaction weight matrix and ranked list that will be used as the
# primary input for the subsequent PBN inference stage.
#
# REVISION:
# This version is adapted to load data from the 'final_clean_counts.csv'
# file and use the gene list from the weighted multi-factor scoring script.
# ===================================================================

# --- 1. Load Required Libraries ---
library(DESeq2)
library(doParallel)
library(doRNG)
library(reshape2)

cat("--- Starting Final Interaction Ranking for Core Gene Set ---\n")

# --- 2. Load Data and Final Gene List ---
cat("\nStep 1: Loading final core gene list and raw count data...\n")

# Load the master gene list generated by the weighted ranking script.
tryCatch({
  final_gene_list <- read.table("core_gene_list.txt", stringsAsFactors = FALSE)$V1
}, error = function(e) { stop("Could not load 'core_gene_list_v2.txt'. Please ensure this file is in the working directory.") })

# --- MODIFIED SECTION: Load the count data from the CSV file ---
tryCatch({
  count_data <- read.csv("final_clean_counts.csv", header = TRUE, row.names = 1)
}, error = function(e) { stop("Could not load 'final_clean_counts.csv'. Please ensure this file is in the working directory.") })
# --- END MODIFIED SECTION ---


# --- 3. Filter and Normalize Data for the Core Gene Set ---
cat("\nStep 2: Filtering and normalizing data for the core gene set...\n")

# Filter the full count matrix to retain only the selected core genes.
filtered_counts <- count_data[rownames(count_data) %in% final_gene_list, ]
cat(sprintf("Filtered data to the final %d core genes.\n", nrow(filtered_counts)))

# Create metadata and apply Variance Stabilizing Transformation (VST).
# This normalization is crucial for the proper functioning of dynGENIE3.
coldata <- data.frame(condition = ifelse(grepl("sensitive", colnames(filtered_counts)), "sensitive", "resistant"))
rownames(coldata) <- colnames(filtered_counts)
dds <- DESeqDataSetFromMatrix(countData = filtered_counts, colData = coldata, design = ~ 1)
vst_data <- assay(varianceStabilizingTransformation(dds, blind = FALSE))


# --- 4. Run dynGENIE3 on the Core Gene Set ---
cat("\nStep 3: Running dynGENIE3 on the core gene set to get final weights...\n")

# Source the script containing the dynGENIE3 function.
source("dynGENIE3.R") 

# Prepare the data for dynGENIE3. We treat all samples as a single time series.
TS.data <- list(vst_data)
time.points <- list(1:ncol(vst_data))

# Set up parallel processing to speed up the computation.
cl <- makeCluster(4)
registerDoParallel(cl)

# Run dynGENIE3. It will infer regulatory links between all genes in our core set.
dynGENIE3_results <- dynGENIE3(TS.data = TS.data, time.points = time.points)

# Stop the parallel cluster.
stopCluster(cl)
cat("dynGENIE3 analysis complete.\n")


# --- 5. Save the Final Ranked Interaction List ---
cat("\nStep 4: Saving the final ranked interaction list for PBN inference...\n")

# Extract the weight matrix from the results.
weight_matrix <- dynGENIE3_results$weight.matrix

# Convert the matrix into a long-format "link list" (source, target, weight).
link_list <- get.link.list(weight_matrix)

# Order the interactions from strongest to weakest based on the inferred weight.
ranked_interactions <- link_list[order(link_list$weight, decreasing = TRUE), ]

# Define the output filename and save the ranked list as a CSV file.
output_file <- "dynGENIE3_ranked_interactions_core_v2.csv"
write.csv(ranked_interactions, file = output_file, row.names = FALSE)

cat(sprintf("\nSuccessfully saved final ranked interaction list to: %s\n", output_file))
cat("This file is the main input for the PBN model inference stage.\n")
cat("\n--- Final Interaction Ranking Complete! ---\n")